{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Implement TOPSIS method and entropy weight method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TOPSIS Method: Use the data of research institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data and weights\n",
    "A = [0.1, 5, 5000, 4.7]\n",
    "B = [0.2, 6, 6000, 5.6]\n",
    "C = [0.4, 7, 7000, 6.7]\n",
    "D = [0.9, 10, 10000, 2.3]\n",
    "E = [1.2, 2, 400, 1.8]\n",
    "data = [A, B, C, D, E]\n",
    "### pubishment, ratio of students to teachers, funds, deferred graduation rate\n",
    "weights = [0.2, 0.3, 0.4, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "- For the four criteria, publishment and funds are large preferred, the ratio is small preferred, funds are preferred in a particular bound.\n",
    "- For the criterion of the ratio of students to teachers, we assume the best field would be [5,6], ratio under 2 or over 12 (inclusive) will get score of 0.\n",
    "- For the criterion of deferred, we takes the reciprocal of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### process the ratio data and deffered graduation rate data.\n",
    "def range2max(rangevalue, num):\n",
    "    lowest, highest, best_range_left, best_range_right = deepcopy(rangevalue)\n",
    "    if num >= best_range_left and num <= best_range_right:\n",
    "        return 1\n",
    "    elif num < best_range_left:\n",
    "        return (num - lowest) / (best_range_left - lowest)\n",
    "    elif num > best_range_right:\n",
    "        return (highest - num) / (highest - best_range_right)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def min2max(num):\n",
    "    return 1/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========distances============\n",
      "distance_plus: [0.40698357 0.36817733 0.31587852 0.23934202 0.53135666]\n",
      "distance_minus: [0.38455211 0.40935987 0.40556474 0.50296763 0.3549938 ]\n",
      "=========final scores============\n",
      "The score of school A is 0.485830\n",
      "The score of school B is 0.526483\n",
      "The score of school C is 0.562158\n",
      "The score of school D is 0.677571\n",
      "The score of school E is 0.400512\n"
     ]
    }
   ],
   "source": [
    "def process_data(data):\n",
    "    ### fist determine the values\n",
    "    columns = [1, 3, ...] # columns needed to merge\n",
    "    rangevalue = [(2, 12, 5, 6), ...] # lowest, highest, best_range_left, best_range_right\n",
    "    ### Merge the data.\n",
    "    m_data = deepcopy(data)\n",
    "    for row in m_data:\n",
    "        row[columns[0]] = range2max(rangevalue[0], row[columns[0]])\n",
    "        row[columns[1]] = min2max(row[columns[1]])\n",
    "    m_data = np.array(m_data)\n",
    "    ### Normalize the data into [0,1]\n",
    "    norm_data = deepcopy(m_data)\n",
    "    for i in range(norm_data.shape[1]):\n",
    "        norm_data[:, i] = norm_data[:, i]/np.sqrt(np.sum(norm_data[:, i]**2))\n",
    "    ### Get ideal data in normalized real data\n",
    "    ideal_bad = [min(norm_data[:, i]) for i in range(norm_data.shape[1])]\n",
    "    ideal_good = [max(norm_data[:, i]) for i in range(norm_data.shape[1])]\n",
    "    ### Calculate the distance between real data and ideal data\n",
    "    distance_plus = np.array([])\n",
    "    distance_minus = np.array([])\n",
    "    for i in range(norm_data.shape[0]):\n",
    "        distance_plus = np.append(distance_plus, np.sqrt(np.sum(np.dot((norm_data[i] - ideal_good)**2, weights))))\n",
    "        distance_minus = np.append(distance_minus, np.sqrt(np.sum(np.dot((norm_data[i] - ideal_bad)**2, weights))))\n",
    "    print(\"=========distances============\")\n",
    "    print(\"distance_plus: {}\".format(distance_plus))\n",
    "    print(\"distance_minus: {}\".format(distance_minus))\n",
    "    print(\"=========final scores============\")\n",
    "    ### Calculate the score\n",
    "    scores = distance_minus / (distance_minus + distance_plus)\n",
    "    for i in range(norm_data.shape[0]):\n",
    "        print(\"The score of school %s is %f\" % (chr(65 + i), scores[i]))\n",
    "\n",
    "process_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now every criterion has turned into large-preferred data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entropy Weight Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100. ,  90. , 100. ,  84. ,  90. , 100. , 100. , 100. , 100. ],\n",
       "       [100. , 100. ,  78.6, 100. ,  90. , 100. , 100. , 100. , 100. ],\n",
       "       [ 75. , 100. ,  85.7, 100. ,  90. , 100. , 100. , 100. , 100. ],\n",
       "       [100. , 100. ,  78.6, 100. ,  90. , 100. ,  94.4, 100. , 100. ],\n",
       "       [100. ,  90. , 100. , 100. , 100. ,  90. , 100. , 100. ,  80. ],\n",
       "       [100. , 100. , 100. , 100. ,  90. , 100. , 100. ,  85.7, 100. ],\n",
       "       [100. , 100. ,  78.6, 100. ,  90. , 100. ,  55.6, 100. , 100. ],\n",
       "       [ 87.5, 100. ,  85.7, 100. , 100. , 100. , 100. , 100. , 100. ],\n",
       "       [100. , 100. ,  92.9, 100. ,  80. , 100. , 100. , 100. , 100. ],\n",
       "       [100. ,  90. , 100. , 100. , 100. , 100. , 100. , 100. , 100. ],\n",
       "       [100. , 100. ,  92.9, 100. ,  90. , 100. , 100. , 100. , 100. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load data\n",
    "A = [100, 90, 100, 84, 90, 100, 100, 100, 100]\n",
    "B = [100, 100, 78.6, 100, 90, 100, 100, 100, 100]\n",
    "C = [75, 100, 85.7, 100, 90, 100, 100, 100, 100]\n",
    "D = [100, 100, 78.6, 100, 90, 100, 94.4, 100, 100]\n",
    "E = [100, 90, 100, 100, 100, 90, 100, 100, 80]\n",
    "F = [100, 100, 100, 100, 90, 100, 100, 85.7, 100]\n",
    "G = [100, 100, 78.6, 100, 90, 100, 55.6, 100, 100]\n",
    "H = [87.5, 100, 85.7, 100, 100, 100, 100, 100, 100]\n",
    "I = [100, 100, 92.9, 100, 80, 100, 100, 100, 100]\n",
    "J = [100, 90, 100, 100, 100, 100, 100, 100, 100]\n",
    "K = [100, 100, 92.9, 100, 90, 100, 100, 100, 100]\n",
    "data = [A, B, C, D, E, F, G, H, I, J, K]\n",
    "data = np.array(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights are: [0.07578559 0.2191587  0.27137381 0.06559212 0.1051977  0.06559212\n",
      " 0.06611572 0.06559212 0.06559212]\n"
     ]
    }
   ],
   "source": [
    "### Calculate weights from 0 to 1\n",
    "### integrate the method into a function\n",
    "def calc_weights(data):\n",
    "    ### first normalize the data\n",
    "    for i in range(data.shape[1]):\n",
    "        data[:, i] = (data[:, i] - min(data[:, i])) / (max(data[:, i]) - min(data[:, i]))\n",
    "    norm_data = data\n",
    "    ### calculate possibilities\n",
    "    possibilities = np.zeros((data.shape[0], data.shape[1]))\n",
    "    prob_log_prob = np.zeros((data.shape[0], data.shape[1]))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            possibilities[i, j] = norm_data[i, j] / np.sum(norm_data[:, j])\n",
    "            prob_log_prob[i, j] = possibilities[i, j] * np.log(possibilities[i, j]) if possibilities[i, j] != 0 else 0\n",
    "    entropy = np.zeros(data.shape[1])\n",
    "    ### To handle the zero case, we use the prob_log_prob to calculate the entropy\n",
    "    for i in range(data.shape[1]):\n",
    "        entropy[i] = -np.sum(prob_log_prob[:, i])/np.log(data.shape[0])\n",
    "    duplicates = 1 - entropy\n",
    "    weights = duplicates / np.sum(duplicates)\n",
    "    return weights\n",
    "weights = calc_weights(data)\n",
    "print(\"The weights are: {}\".format(weights))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('SILENT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:41:22) [Clang 13.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "33a00747c7c616a6e1f951908c7a8e16aa8bdee44e4bbac794a20c5a719e4c26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
